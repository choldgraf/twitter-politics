{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import process\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "# Import a list of states\n",
    "from states import states as all_states\n",
    "all_states = [ii.lower() for ii in all_states.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congresspeople Twitter\n",
    "First we'll pull the twitter handles for active congresspeople from a list curated by [CSPAN](http://twitter.com/CSPAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to twitter\n",
    "keys = dict(consumer_key=os.environ['TWITTER_KEY'],\n",
    "            consumer_secret=os.environ['TWITTER_SECRET'],\n",
    "            access_token_key=os.environ['TWITTER_ACCESS_TOKEN_KEY'],\n",
    "            access_token_secret=os.environ['TWITTER_ACCESS_TOKEN_SECRET'])\n",
    "api = TwitterAPI(**keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the ID for this list\n",
    "slug = \"members-of-congress\"\n",
    "handle = \"cspan\"\n",
    "resp = api.request('lists/ownerships', params=dict(screen_name=handle))\n",
    "this_list = [ii for ii in resp.json()['lists'] if ii['slug'] == slug][0]\n",
    "this_list_id = this_list['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now pull the actual list\n",
    "resp = api.request(\"lists/members\",\n",
    "                   params=dict(list_id=this_list_id, count=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove text relating just to the job title\n",
    "jobs = {'senator': ['senate', 'sen'],\n",
    "        'representative': ['representative', 'rep']}\n",
    "\n",
    "# Prep names for matching\n",
    "congresspeople_twitter = []\n",
    "for person in resp:\n",
    "    handle = person['screen_name']\n",
    "    name = person['name']\n",
    "\n",
    "    congresspeople_twitter.append(dict(name=name.lower(),\n",
    "                                  handle=handle))\n",
    "\n",
    "# Collect and save    \n",
    "congresspeople_twitter = pd.DataFrame(congresspeople_twitter)\n",
    "congresspeople_twitter.to_csv('../data/congressperson_twitter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congresspeople Information\n",
    "Now we'll pull information about each congressperson's state / party affiliation. We'll use the information stored in the (excellent) website [ballotpedia](https://ballotpedia.org/List_of_current_members_of_the_U.S._Congress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://ballotpedia.org/List_of_current_members_of_the_U.S._Congress\"\n",
    "congress = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use beautifulsoup to parse the output and collect information we want\n",
    "html = bs(congress.text, 'html5lib')\n",
    "tables = html.find_all('table', attrs={'class': 'wikitable'})\n",
    "\n",
    "congresspeople_info = []\n",
    "for body, table in zip(['senate', 'house'], tables):\n",
    "    people = table.find_all('tr') \n",
    "    for person in people[1:]:\n",
    "        name, yrs, party, state, end = person.find_all('td')\n",
    "        name, yrs, party, state, end = [ii.text.strip().lower()\n",
    "                                        for ii in (name, yrs, party, state, end)]\n",
    "        congresspeople_info.append(dict(name=name, yrs=yrs, body=body,\n",
    "                                        party=party, state=state, end=end))\n",
    "congresspeople_info = pd.DataFrame(congresspeople_info)\n",
    "\n",
    "# Now save to disk\n",
    "congresspeople_info.to_csv('../data/congressperson_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter = pd.read_csv('../data/congressperson_twitter.csv', index_col=0)\n",
    "info = pd.read_csv('../data/congressperson_info.csv', index_col=0)\n",
    "\n",
    "# Split state and district\n",
    "for ii, row in info.iterrows():\n",
    "    if row['body'] == 'house':\n",
    "        state = [istate for istate in all_states if istate in row['state']]\n",
    "        state = None if len(state) == 0 else state[0]\n",
    "        \n",
    "        district = row['state'].split('district')[-1].split(' ')[-1]\n",
    "        info.loc[ii, 'state'] = state\n",
    "        info.loc[ii, 'district'] = district\n",
    "\n",
    "# Remove unnecessary text\n",
    "remove_text = ['senator', 'rep.', 'u.s.']\n",
    "for txt in remove_text:\n",
    "    twitter['name'] = twitter['name'].str.replace(txt, '')\n",
    "twitter['name'] = twitter['name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 533/533 [00:32<00:00, 16.38it/s]\n",
      "100%|██████████| 86/86 [00:06<00:00,  5.92it/s]\n",
      "100%|██████████| 36/36 [00:05<00:00,  6.76it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 16.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find and merge the twitter information and the rep information\n",
    "# We'll use the `fuzzywuzzy` package for this.\n",
    "twitter_iter = twitter.copy()\n",
    "person_names = info['name'].values\n",
    "\n",
    "# On each step, fuzzywuzzy will pick the 'best' name match\n",
    "# We'll on keep it if we're very confident in the match\n",
    "# On each iteration, we'll loosen this confidence level\n",
    "confidence_requirements = [90, 85, 80, 75]\n",
    "matches = []\n",
    "for conf in confidence_requirements:\n",
    "    for name in tqdm(person_names):\n",
    "        best_name, best_conf = process.extractBests(name, twitter_iter['name'].values)[0]\n",
    "        if best_conf > conf:\n",
    "            # Find the handle for this name\n",
    "            handle = twitter_iter.query('name == @best_name')['handle'].values[0]\n",
    "            \n",
    "            # Remove that entry from names\n",
    "            twitter_names = twitter_iter[twitter_iter['name'].values != best_name]\n",
    "            person_names = person_names[person_names != name]\n",
    "            matches.append({'name': name,\n",
    "                            'twitter_name': best_name,\n",
    "                            'conf': best_conf,\n",
    "                            'handle': handle})\n",
    "matches = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put it all together\n",
    "info_with_twitter = info.merge(matches, how='outer', on='name').sort_values('conf')\n",
    "\n",
    "# Make sure missing states are `None`\n",
    "for ii, person in info_with_twitter.iterrows():\n",
    "    if person['state'] not in all_states:\n",
    "        info_with_twitter.loc[ii, 'state'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent people matched: 95.31%\n"
     ]
    }
   ],
   "source": [
    "# Now save to disk\n",
    "percent_matches = 1 - pd.isnull(info_with_twitter['handle']).sum() / float(info_with_twitter.shape[0])\n",
    "print('Percent people matched: {:.2f}%'.format(percent_matches * 100))\n",
    "\n",
    "info_with_twitter.to_csv('../data/congressperson_all_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
